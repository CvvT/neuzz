{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "import socket\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "argvv = ['./test']\n",
    "seed_list = glob.glob('./neuzz_in/*')\n",
    "seed_list.sort()\n",
    "SPLIT_RATIO = len(seed_list)\n",
    "rand_index = np.arange(SPLIT_RATIO)\n",
    "np.random.shuffle(seed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./neuzz_in/id:000090,src:000088,op:int8,pos:41,val:+0,+cov\n",
      "./neuzz_in/id:000027,src:000025,op:flip1,pos:10,+cov\n",
      "./neuzz_in/id:000002,src:000000,op:flip4,pos:5\n",
      "./neuzz_in/id:000029,src:000027,op:arith8,pos:11,val:+15,+cov\n",
      "./neuzz_in/id:000083,src:000081,op:arith8,pos:38,val:+20,+cov\n",
      "./neuzz_in/id:000070,src:000067,op:int8,pos:31,val:+0,+cov\n",
      "./neuzz_in/id:000119,src:000117,op:flip2,pos:56,+cov\n",
      "./neuzz_in/id:000110,src:000107,op:int8,pos:51,val:+0,+cov\n",
      "./neuzz_in/id:000061,src:000059,op:flip4,pos:27,+cov\n",
      "./neuzz_in/id:000109,src:000107,op:arith8,pos:51,val:+21,+cov\n",
      "./neuzz_in/id:000036,src:000033,op:int8,pos:14,val:+0,+cov\n",
      "./neuzz_in/id:000059,src:000057,op:flip2,pos:26,+cov\n",
      "./neuzz_in/id:000011,src:000010,op:flip1,pos:2,+cov\n",
      "./neuzz_in/id:000045,src:000043,op:arith8,pos:19,val:+21,+cov\n",
      "./neuzz_in/id:000121,src:000119,op:arith8,pos:57,val:-14,+cov\n",
      "./neuzz_in/id:000132,src:000130,op:int8,pos:62,val:+0,+cov\n",
      "./neuzz_in/id:000133,src:000131,op:arith8,pos:63,val:+11,+cov\n",
      "./neuzz_in/id:000031,src:000029,op:havoc,rep:2,+cov\n",
      "./neuzz_in/id:000028,src:000025,op:int8,pos:10,val:+0,+cov\n",
      "./neuzz_in/id:000001,src:000000,op:flip2,pos:9\n",
      "./neuzz_in/id:000065,src:000064,op:arith8,pos:29,val:+21,+cov\n",
      "./neuzz_in/id:000127,src:000125,op:flip2,pos:60,+cov\n",
      "./neuzz_in/id:000019,src:000017,op:arith8,pos:6,val:+13,+cov\n",
      "./neuzz_in/id:000000,orig:test\n",
      "./neuzz_in/id:000025,src:000024,op:flip1,pos:9,+cov\n",
      "./neuzz_in/id:000115,src:000113,op:arith8,pos:54,val:-7,+cov\n",
      "./neuzz_in/id:000020,src:000017+000009,op:splice,rep:2,+cov\n",
      "./neuzz_in/id:000097,src:000095,op:flip2,pos:45,+cov\n",
      "./neuzz_in/id:000093,src:000092,op:flip4,pos:43,+cov\n",
      "./neuzz_in/id:000108,src:000105,op:int8,pos:50,val:+0,+cov\n",
      "./neuzz_in/id:000008,src:000000,op:havoc,rep:64,+cov\n",
      "./neuzz_in/id:000073,src:000071,op:arith8,pos:33,val:+27,+cov\n",
      "./neuzz_in/id:000067,src:000065,op:flip2,pos:30,+cov\n",
      "./neuzz_in/id:000088,src:000085,op:flip4,pos:40,+cov\n",
      "./neuzz_in/id:000047,src:000044+000045,op:splice,rep:4,+cov\n",
      "./neuzz_in/id:000069,src:000067,op:flip4,pos:31,+cov\n",
      "./neuzz_in/id:000058,src:000056,op:int8,pos:25,val:+0,+cov\n",
      "./neuzz_in/id:000046,src:000043,op:int8,pos:19,val:+0,+cov\n",
      "./neuzz_in/id:000043,src:000042,op:flip1,pos:18,+cov\n",
      "./neuzz_in/id:000103,src:000101,op:arith8,pos:48,val:-13,+cov\n",
      "./neuzz_in/id:000003,src:000000,op:int8,pos:0,val:+0,+cov\n",
      "./neuzz_in/id:000024,src:000023,op:arith8,pos:8,val:-7,+cov\n",
      "./neuzz_in/id:000117,src:000115,op:arith8,pos:55,val:+13,+cov\n",
      "./neuzz_in/id:000021,src:000020,op:flip1,pos:7,+cov\n",
      "./neuzz_in/id:000126,src:000123,op:int8,pos:59,val:+0,+cov\n",
      "./neuzz_in/id:000054,src:000051,op:int8,pos:23,val:+0,+cov\n",
      "./neuzz_in/id:000048,src:000045,op:arith8,pos:20,val:+23,+cov\n",
      "./neuzz_in/id:000089,src:000088,op:arith8,pos:41,val:-19,+cov\n",
      "./neuzz_in/id:000124,src:000121,op:int8,pos:58,val:+0,+cov\n",
      "./neuzz_in/id:000018,src:000016,op:int8,pos:5,val:+0,+cov\n",
      "./neuzz_in/id:000040,src:000039,op:arith8,pos:16,val:-12,+cov\n",
      "./neuzz_in/id:000112,src:000109,op:int8,pos:52,val:+0,+cov\n",
      "./neuzz_in/id:000091,src:000088,op:int16,pos:41,val:+100,+cov\n",
      "./neuzz_in/id:000092,src:000089,op:arith8,pos:42,val:+18,+cov\n",
      "./neuzz_in/id:000042,src:000040,op:havoc,rep:4,+cov\n",
      "./neuzz_in/id:000063,src:000061,op:arith8,pos:28,val:+30,+cov\n",
      "./neuzz_in/id:000085,src:000083,op:flip2,pos:39,+cov\n",
      "./neuzz_in/id:000033,src:000032,op:arith8,pos:13,val:-2,+cov\n",
      "./neuzz_in/id:000060,src:000057,op:int8,pos:26,val:+0,+cov\n",
      "./neuzz_in/id:000106,src:000103,op:int8,pos:49,val:+0,+cov\n",
      "./neuzz_in/id:000095,src:000094,op:arith8,pos:44,val:+9,+cov\n",
      "./neuzz_in/id:000056,src:000053,op:havoc,rep:4,+cov\n",
      "./neuzz_in/id:000078,src:000075,op:int8,pos:35,val:+0,+cov\n",
      "./neuzz_in/id:000038,src:000035,op:flip4,pos:15,+cov\n",
      "./neuzz_in/id:000022,src:000020,op:arith8,pos:7,val:-7,+cov\n",
      "./neuzz_in/id:000057,src:000056,op:arith8,pos:25,val:+13,+cov\n",
      "./neuzz_in/id:000039,src:000035,op:havoc,rep:2,+cov\n",
      "./neuzz_in/id:000131,src:000130,op:arith8,pos:62,val:-9,+cov\n",
      "./neuzz_in/id:000044,src:000042,op:int8,pos:18,val:+0,+cov\n",
      "./neuzz_in/id:000023,src:000022,op:havoc,rep:2,+cov\n",
      "./neuzz_in/id:000074,src:000071+000057,op:splice,rep:2,+cov\n",
      "./neuzz_in/id:000017,src:000016,op:flip4,pos:5,+cov\n",
      "./neuzz_in/id:000111,src:000109,op:arith8,pos:52,val:-20,+cov\n",
      "./neuzz_in/id:000051,src:000049,op:arith8,pos:22,val:+13,+cov\n",
      "./neuzz_in/id:000034,src:000032,op:int8,pos:13,val:+0,+cov\n",
      "./neuzz_in/id:000049,src:000048,op:arith8,pos:21,val:+21,+cov\n",
      "./neuzz_in/id:000114,src:000111,op:int8,pos:53,val:+0,+cov\n",
      "./neuzz_in/id:000107,src:000105,op:flip2,pos:50,+cov\n",
      "./neuzz_in/id:000053,src:000051,op:flip2,pos:23,+cov\n",
      "./neuzz_in/id:000123,src:000121,op:arith8,pos:58,val:+15,+cov\n",
      "./neuzz_in/id:000072,src:000069,op:havoc,rep:2,+cov\n",
      "./neuzz_in/id:000062,src:000059,op:int8,pos:27,val:+0,+cov\n",
      "./neuzz_in/id:000026,src:000024,op:int8,pos:9,val:+0,+cov\n",
      "./neuzz_in/id:000055,src:000053,op:havoc,rep:4,+cov\n",
      "./neuzz_in/id:000014,src:000013,op:arith8,pos:3,val:-15,+cov\n",
      "./neuzz_in/id:000080,src:000079,op:arith8,pos:36,val:+7,+cov\n",
      "./neuzz_in/id:000082,src:000080,op:int8,pos:37,val:+0,+cov\n",
      "./neuzz_in/id:000041,src:000040,op:int8,pos:17,val:+0,+cov\n",
      "./neuzz_in/id:000101,src:000099,op:arith8,pos:47,val:-10,+cov\n",
      "./neuzz_in/id:000015,src:000013,op:havoc,rep:8,+cov\n",
      "./neuzz_in/id:000050,src:000048,op:int8,pos:21,val:+0,+cov\n",
      "./neuzz_in/id:000087,src:000085,op:flip4,pos:40,+cov\n",
      "./neuzz_in/id:000076,src:000074,op:int8,pos:34,val:+0,+cov\n",
      "./neuzz_in/id:000068,src:000065,op:int8,pos:30,val:+0,+cov\n",
      "./neuzz_in/id:000013,src:000012,op:flip1,pos:3,+cov\n",
      "./neuzz_in/id:000077,src:000075,op:arith8,pos:35,val:+10,+cov\n",
      "./neuzz_in/id:000005,src:000000,op:havoc,rep:64\n",
      "./neuzz_in/id:000134,src:000131,op:int8,pos:63,val:+0,+cov\n",
      "./neuzz_in/id:000016,src:000015,op:arith8,pos:4,val:-12,+cov\n",
      "./neuzz_in/id:000030,src:000027,op:int8,pos:11,val:+0,+cov\n",
      "./neuzz_in/id:000079,src:000077,op:havoc,rep:2,+cov\n",
      "./neuzz_in/id:000116,src:000113,op:int8,pos:54,val:+0,+cov\n",
      "./neuzz_in/id:000118,src:000115,op:int8,pos:55,val:+0,+cov\n",
      "./neuzz_in/id:000075,src:000074,op:arith8,pos:34,val:+14,+cov\n",
      "./neuzz_in/id:000130,src:000127,op:arith8,pos:61,val:-2,+cov\n",
      "./neuzz_in/id:000104,src:000101,op:int8,pos:48,val:+0,+cov\n",
      "./neuzz_in/id:000120,src:000117,op:int8,pos:56,val:+0,+cov\n",
      "./neuzz_in/id:000010,src:000009,op:arith8,pos:1,val:-33,+cov\n",
      "./neuzz_in/id:000064,src:000062,op:havoc,rep:8,+cov\n",
      "./neuzz_in/id:000084,src:000081,op:int8,pos:38,val:+0,+cov\n",
      "./neuzz_in/id:000128,src:000125,op:int8,pos:60,val:+0,+cov\n",
      "./neuzz_in/id:000105,src:000103,op:arith8,pos:49,val:-22,+cov\n",
      "./neuzz_in/id:000086,src:000083,op:int8,pos:39,val:+0,+cov\n",
      "./neuzz_in/id:000122,src:000119,op:int8,pos:57,val:+0,+cov\n",
      "./neuzz_in/id:000012,src:000011,op:havoc,rep:2,+cov\n",
      "./neuzz_in/id:000100,src:000097,op:int8,pos:46,val:+0,+cov\n",
      "./neuzz_in/id:000081,src:000080,op:arith8,pos:37,val:-14,+cov\n",
      "./neuzz_in/id:000129,src:000125,op:int16,pos:60,val:+100,+cov\n",
      "./neuzz_in/id:000102,src:000099,op:int8,pos:47,val:+0,+cov\n",
      "./neuzz_in/id:000037,src:000033,op:int16,pos:14,val:+100,+cov\n",
      "./neuzz_in/id:000009,src:000000,op:havoc,rep:64,+cov\n",
      "./neuzz_in/id:000007,src:000000,op:havoc,rep:4\n",
      "./neuzz_in/id:000035,src:000033,op:arith8,pos:14,val:+3,+cov\n",
      "./neuzz_in/id:000066,src:000064,op:int8,pos:29,val:+0,+cov\n",
      "./neuzz_in/id:000052,src:000049,op:int8,pos:22,val:+0,+cov\n",
      "./neuzz_in/id:000098,src:000095,op:int8,pos:45,val:+0,+cov\n",
      "./neuzz_in/id:000099,src:000097,op:flip2,pos:46,+cov\n",
      "./neuzz_in/id:000096,src:000094,op:int8,pos:44,val:+0,+cov\n",
      "./neuzz_in/id:000113,src:000111,op:arith8,pos:53,val:-5,+cov\n",
      "./neuzz_in/id:000125,src:000123,op:arith8,pos:59,val:-30,+cov\n",
      "./neuzz_in/id:000071,src:000069,op:flip4,pos:32,+cov\n",
      "./neuzz_in/id:000004,src:000000,op:int8,pos:120,val:+0\n",
      "./neuzz_in/id:000006,src:000000,op:havoc,rep:128\n",
      "./neuzz_in/id:000094,src:000092,op:arith8,pos:43,val:-21,+cov\n",
      "./neuzz_in/id:000032,src:000031,op:arith8,pos:12,val:+11,+cov\n"
     ]
    }
   ],
   "source": [
    "MAX_FILE_SIZE = 512\n",
    "call=subprocess.check_output\n",
    "raw_bitmap = {}\n",
    "tmp_cnt = []\n",
    "out = ''\n",
    "for f in seed_list:\n",
    "    tmp_list = []\n",
    "    try:\n",
    "        # append \"-o tmp_file\" to strip's arguments to avoid tampering tested binary.\n",
    "        print(f)\n",
    "        with open(f) as myinput:\n",
    "            out = call(['./afl-showmap', '-q', '-e', '-o', '/dev/stdout', '-m', '512'] + argvv, stdin=myinput)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"find a crash\")\n",
    "    for line in out.splitlines():\n",
    "        edge = line.split(':')[0]\n",
    "        tmp_cnt.append(edge)\n",
    "        tmp_list.append(edge)\n",
    "    raw_bitmap[f] = tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(tmp_cnt).most_common()\n",
    "label = [int(f[0]) for f in counter]\n",
    "bitmap = np.zeros((len(seed_list), len(label)))\n",
    "for idx,i in enumerate(seed_list):\n",
    "    tmp = raw_bitmap[i]\n",
    "    for j in tmp:\n",
    "        if int(j) in label:\n",
    "            bitmap[idx][label.index((int(j)))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_bitmap = np.unique(bitmap,axis=1)\n",
    "MAX_BITMAP_SIZE = fit_bitmap.shape[1]\n",
    "for idx,i in enumerate(seed_list):\n",
    "    file_name = \"./bitmaps/\"+i.split('/')[-1]\n",
    "    np.save(file_name,fit_bitmap[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_label = []\n",
    "for i in range(fit_bitmap.shape[1]):\n",
    "    edges = []\n",
    "    for j in range(bitmap.shape[1]):\n",
    "        if (bitmap[:, j] == fit_bitmap[:, i]).all():\n",
    "            edges.append(j)\n",
    "    fit_label.append(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(edge):\n",
    "    index = label.index(edge)\n",
    "    for i, edges in enumerate(fit_label):\n",
    "        if index in edges:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accur_1(y_true,y_pred):\n",
    "    y_true = tf.round(y_true)\n",
    "    pred = tf.round(y_pred)\n",
    "    summ = tf.constant(MAX_BITMAP_SIZE,dtype=tf.float32)\n",
    "    wrong_num = tf.subtract(summ,tf.reduce_sum(tf.cast(tf.equal(y_true, pred),tf.float32),axis=-1))\n",
    "    right_1_num = tf.reduce_sum(tf.cast(tf.logical_and(tf.cast(y_true,tf.bool), tf.cast(pred,tf.bool)),tf.float32),axis=-1)\n",
    "    ret = K.mean(tf.divide(right_1_num,tf.add(right_1_num,wrong_num)))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    batch_size = 32\n",
    "    num_classes = MAX_BITMAP_SIZE\n",
    "    epochs = 50\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4096, input_dim=MAX_FILE_SIZE))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    opt = keras.optimizers.adam(lr=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[accur_1])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 258)               1057026   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 258)               0         \n",
      "=================================================================\n",
      "Total params: 3,158,274\n",
      "Trainable params: 3,158,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(lb,ub):\n",
    "    seed = np.zeros((ub-lb,MAX_FILE_SIZE))\n",
    "    bitmap = np.zeros((ub-lb,MAX_BITMAP_SIZE))\n",
    "    for i in range(lb,ub):\n",
    "        tmp = open(seed_list[i],'r').read()\n",
    "        ln = len(tmp)\n",
    "        if ln < MAX_FILE_SIZE:\n",
    "            tmp = tmp + (MAX_FILE_SIZE - ln) * '\\0'\n",
    "        seed[i-lb] = [ord(j) for j in list(tmp)]\n",
    "    for i in range(lb,ub):\n",
    "        file_name = \"./bitmaps/\"+ seed_list[i].split('/')[-1] + \".npy\"\n",
    "        bitmap[i-lb] = np.load(file_name)\n",
    "    return seed,bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generate(batch_size):\n",
    "    global seed_list\n",
    "    while 1:\n",
    "        np.random.shuffle(seed_list)\n",
    "        for i in range(0,SPLIT_RATIO,batch_size):\n",
    "            if (i+batch_size) > SPLIT_RATIO:\n",
    "                x,y=generate_training_data(i,SPLIT_RATIO)\n",
    "                x = x.astype('float32')/255\n",
    "            else:\n",
    "                x,y=generate_training_data(i,i+batch_size)\n",
    "                x = x.astype('float32')/255\n",
    "            yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))\n",
    "        print(step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.7\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    loss_history = LossHistory()\n",
    "    lrate = keras.callbacks.LearningRateScheduler(step_decay)\n",
    "    callbacks_list = [loss_history, lrate]\n",
    "    model.fit_generator(train_generate(8),\n",
    "              steps_per_epoch = (SPLIT_RATIO/8 + 1),\n",
    "              epochs=100,\n",
    "              verbose=1, callbacks=callbacks_list)\n",
    "    # Save model and weights\n",
    "    model.save_weights(\"hard_label.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0767 - accur_1: 0.8526\n",
      "0.001\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0790 - accur_1: 0.8502\n",
      "0.001\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0741 - accur_1: 0.8585\n",
      "0.001\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0751 - accur_1: 0.8595\n",
      "0.001\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0736 - accur_1: 0.8500\n",
      "0.001\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0803 - accur_1: 0.8414\n",
      "0.001\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0897 - accur_1: 0.8342\n",
      "0.001\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0716 - accur_1: 0.8544\n",
      "0.001\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0685 - accur_1: 0.8624\n",
      "0.0007\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0622 - accur_1: 0.8875\n",
      "0.0007\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0613 - accur_1: 0.8775\n",
      "0.0007\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0641 - accur_1: 0.8783\n",
      "0.0007\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0622 - accur_1: 0.8803\n",
      "0.0007\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0609 - accur_1: 0.8817\n",
      "0.0007\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0569 - accur_1: 0.8929\n",
      "0.0007\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0546 - accur_1: 0.8956\n",
      "0.0007\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0544 - accur_1: 0.9039\n",
      "0.0007\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0525 - accur_1: 0.9071\n",
      "0.0007\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0527 - accur_1: 0.9006\n",
      "0.00049\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0526 - accur_1: 0.8988\n",
      "0.00049\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0526 - accur_1: 0.8978\n",
      "0.00049\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0495 - accur_1: 0.9085\n",
      "0.00049\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0494 - accur_1: 0.9094\n",
      "0.00049\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0491 - accur_1: 0.9099\n",
      "0.00049\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0477 - accur_1: 0.9118\n",
      "0.00049\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0477 - accur_1: 0.9138\n",
      "0.00049\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0487 - accur_1: 0.9117\n",
      "0.00049\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0478 - accur_1: 0.9128\n",
      "0.00049\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0459 - accur_1: 0.9122\n",
      "0.000343\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0457 - accur_1: 0.9131\n",
      "0.000343\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0445 - accur_1: 0.9189\n",
      "0.000343\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0453 - accur_1: 0.9129\n",
      "0.000343\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0441 - accur_1: 0.9174\n",
      "0.000343\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0436 - accur_1: 0.9180\n",
      "0.000343\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0448 - accur_1: 0.9130\n",
      "0.000343\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0444 - accur_1: 0.9130\n",
      "0.000343\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0425 - accur_1: 0.9192\n",
      "0.000343\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0427 - accur_1: 0.9146\n",
      "0.000343\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.0434 - accur_1: 0.9186\n",
      "0.0002401\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0414 - accur_1: 0.9200\n",
      "0.0002401\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0424 - accur_1: 0.9154\n",
      "0.0002401\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0410 - accur_1: 0.9217\n",
      "0.0002401\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0409 - accur_1: 0.9217\n",
      "0.0002401\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0421 - accur_1: 0.9203\n",
      "0.0002401\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0413 - accur_1: 0.9172\n",
      "0.0002401\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0413 - accur_1: 0.9194\n",
      "0.0002401\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0406 - accur_1: 0.9205\n",
      "0.0002401\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0412 - accur_1: 0.9174\n",
      "0.0002401\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0408 - accur_1: 0.9240\n",
      "0.00016807\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0394 - accur_1: 0.9216\n",
      "0.00016807\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.0394 - accur_1: 0.9210\n",
      "0.00016807\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0400 - accur_1: 0.9227\n",
      "0.00016807\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0395 - accur_1: 0.9227\n",
      "0.00016807\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0392 - accur_1: 0.9254\n",
      "0.00016807\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0389 - accur_1: 0.9234\n",
      "0.00016807\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0388 - accur_1: 0.9252\n",
      "0.00016807\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0385 - accur_1: 0.9253\n",
      "0.00016807\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0383 - accur_1: 0.9228\n",
      "0.00016807\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0380 - accur_1: 0.9281\n",
      "0.000117649\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0378 - accur_1: 0.9297\n",
      "0.000117649\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0382 - accur_1: 0.9225\n",
      "0.000117649\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0377 - accur_1: 0.9266\n",
      "0.000117649\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0381 - accur_1: 0.9249\n",
      "0.000117649\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0377 - accur_1: 0.9265\n",
      "0.000117649\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0378 - accur_1: 0.9226\n",
      "0.000117649\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0380 - accur_1: 0.9280\n",
      "0.000117649\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.0376 - accur_1: 0.9258\n",
      "0.000117649\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0373 - accur_1: 0.9276\n",
      "0.000117649\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0376 - accur_1: 0.9244\n",
      "8.23543e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0371 - accur_1: 0.9269\n",
      "8.23543e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0369 - accur_1: 0.9279\n",
      "8.23543e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0369 - accur_1: 0.9299\n",
      "8.23543e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0368 - accur_1: 0.9288\n",
      "8.23543e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0367 - accur_1: 0.9249\n",
      "8.23543e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0367 - accur_1: 0.9282\n",
      "8.23543e-05\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0366 - accur_1: 0.9298\n",
      "8.23543e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0368 - accur_1: 0.9290\n",
      "8.23543e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0369 - accur_1: 0.9274\n",
      "8.23543e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0363 - accur_1: 0.9298\n",
      "5.764801e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0362 - accur_1: 0.9290\n",
      "5.764801e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0361 - accur_1: 0.9307\n",
      "5.764801e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0361 - accur_1: 0.9304\n",
      "5.764801e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0361 - accur_1: 0.9302\n",
      "5.764801e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0363 - accur_1: 0.9282\n",
      "5.764801e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0361 - accur_1: 0.9308\n",
      "5.764801e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0361 - accur_1: 0.9305\n",
      "5.764801e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0359 - accur_1: 0.9307\n",
      "5.764801e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.0360 - accur_1: 0.9296\n",
      "5.764801e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0358 - accur_1: 0.9311\n",
      "4.0353607e-05\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0358 - accur_1: 0.9313\n",
      "4.0353607e-05\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.0358 - accur_1: 0.9310\n",
      "4.0353607e-05\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0355 - accur_1: 0.9319\n",
      "4.0353607e-05\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0357 - accur_1: 0.9321\n",
      "4.0353607e-05\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.0357 - accur_1: 0.9314\n",
      "4.0353607e-05\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0358 - accur_1: 0.9317\n",
      "4.0353607e-05\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0357 - accur_1: 0.9309\n",
      "4.0353607e-05\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0356 - accur_1: 0.9325\n",
      "4.0353607e-05\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.0355 - accur_1: 0.9318\n",
      "4.0353607e-05\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0356 - accur_1: 0.9304\n",
      "2.82475249e-05\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0354 - accur_1: 0.9311\n",
      "2.82475249e-05\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_file(fl, isfile, vectorize=True):\n",
    "    seed = np.zeros((1,MAX_FILE_SIZE))\n",
    "    if isfile:\n",
    "        tmp = open(fl,'r').read()\n",
    "    else:\n",
    "        tmp = fl\n",
    "    ln = len(tmp)\n",
    "    if ln < MAX_FILE_SIZE:\n",
    "        tmp = tmp + (MAX_FILE_SIZE - ln) * '\\0'\n",
    "    seed[0] = [ord(j) for j in list(tmp)]\n",
    "    if vectorize:\n",
    "        seed = seed.astype('float32')/255\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(model, edge, seed, isfile, vectorize=True):\n",
    "    layer_list = [(layer.name, layer) for layer in model.layers]\n",
    "    index = getIndex(edge)\n",
    "    loss = layer_list[-2][1].output[:,index]\n",
    "    grads = K.gradients(loss,model.input)[0]\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    x=vectorize_file(seed, isfile, vectorize)\n",
    "    loss_value, grads_value = iterate([x])\n",
    "    idx = np.flip(np.argsort(np.absolute(grads_value),axis=1)[:, -MAX_FILE_SIZE:].reshape((MAX_FILE_SIZE,)),0)\n",
    "    val = np.sign(grads_value[0][idx])\n",
    "    return idx, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  9,  0,  8,  7, 58,  4, 19,  6, 33, 34, 11, 60, 12,  5, 30, 15,\n",
       "       56, 20, 16, 35,  1, 26, 31, 28, 61, 21, 18, 10, 32, 59, 24])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, val = gradient(model, 137, \"xhqxxxxx\", False, True)\n",
    "idx[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  0,  9,  8,  7, 58,  4, 19,  6, 33, 34, 11, 60,  5, 15, 30, 12,\n",
       "       20, 56, 16,  1, 35, 26, 18, 31, 21, 61, 10, 59, 28, 32, 24])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, val = gradient(model, 137, \"xhexxxxx\", False, False)\n",
    "idx[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51,  45,  55,  44,  42,  46,  49,  38,  58,  43,  28,  40,  59,\n",
       "        56,  62,  63,  52,  61,  10,  39,  50,   0,   9,   8,  11,  41,\n",
       "        54,  16,  18,   2,   1,  53,  14,  17,  23,  19,  20,  21,  25,\n",
       "        22,  15,  24,  13,   3,  27,  12,  30,  36,  34,  32,   7,  57,\n",
       "        29,  48,  82,   5,   6,   4,  35, 105,  31,  26, 315, 480])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, val = gradient(model, 46697, \"neuzz_in/id:000134,src:000131,op:int8,pos:63,val:+0,+cov\", True, True)\n",
    "idx[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58, 51, 56, 55, 45, 60,  9,  0, 19, 33,  2, 53, 44, 59, 46, 43,  7,\n",
       "       34, 42, 32, 20, 35, 50, 26,  1,  5, 49, 24, 21, 57, 41, 54])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, val = gradient(model, 46697, \"neuzz_in/id:000134,src:000131,op:int8,pos:63,val:+0,+cov\", True, False)\n",
    "idx[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, seed, vectorize=False):\n",
    "    x = vectorize_file(seed, True, vectorize)\n",
    "    file_name = file_name = \"./bitmaps/\"+ seed.split('/')[-1] + \".npy\"\n",
    "    return model.predict(x), np.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, ty = evaluate(model, \"neuzz_in/id:000134,src:000131,op:int8,pos:63,val:+0,+cov\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.360158e-32,\n",
       "        0.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        0.000000e+00, 1.000000e+00, 1.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuzz",
   "language": "python",
   "name": "neuzz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
